# Pytorchå®˜ç½‘æ•™ç¨‹ç¬”è®°

ğŸ”—ï¼šhttps://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html

## 1. åŸºç¡€çŸ¥è¯†

## 1.1 å¼ é‡ï¼ˆTensorsï¼‰

Tensorsä¸NumPyçš„ndarraysç±»ä¼¼ï¼Œåªæ˜¯tensorsè¿˜å¯ä»¥åœ¨GPUå’Œå…¶ä»–ç¡¬ä»¶åŠ é€Ÿå™¨ä¸Šè¿è¡Œã€‚ä¸¤è€…ç»å¸¸å…±äº«ä¸€æ ·çš„åº•å±‚å†…å­˜ï¼Œä¸éœ€è¦å¤åˆ¶ã€‚


```python
import torch
```


```python
import numpy as np
```

### 1.1.1 åˆå§‹åŒ–Tensor

- å¯ä»¥ç›´æ¥èµ‹å€¼


```python
data = [[1,2],[3,4]]
```


```python
x_data = torch.tensor(data)
```


```python
x_data
```




    tensor([[1, 2],
            [3, 4]])



- å¯ä»¥ä»Numpy arrayèµ‹å€¼


```python
np_array = np.array(data)
```


```python
x_np = torch.from_numpy(np_array)
```


```python
x_np
```




    tensor([[1, 2],
            [3, 4]])



- å¯ä»¥ä»å¦ä¸€ä¸ªTensorèµ‹å€¼


```python
x_ones = torch.ones_like(x_data)
```


```python
print(f"One Tensor: \n {x_ones} \n")
```

    One Tensor: 
     tensor([[1, 1],
            [1, 1]]) 
    



```python
x_rand = torch.rand_like(x_data, dtype = torch.float)
```


```python
print(f"Random Tensor: \n {x_rand} \n")
```

    Random Tensor: 
     tensor([[0.1883, 0.9876],
            [0.9896, 0.8167]]) 
    


- With random or constant values


```python
shape = (2,3,) #tuple
rand_tensor = torch.rand(shape)
ones_tensor = torch.ones(shape)
zeros_tensor = torch.zeros(shape)

print(f"Random Tensor: \n {rand_tensor} \n")
print(f"Ones Tensor: \n {ones_tensor} \n")
print(f"Zeros Tensor: \n {zeros_tensor}")
```

    Random Tensor: 
     tensor([[0.3669, 0.5733, 0.1213],
            [0.3788, 0.0999, 0.7571]]) 
    
    Ones Tensor: 
     tensor([[1., 1., 1.],
            [1., 1., 1.]]) 
    
    Zeros Tensor: 
     tensor([[0., 0., 0.],
            [0., 0., 0.]])


### 1.1.2 Tensorçš„å±æ€§


```python
tensor = torch.rand(3,4)

print(f"Shape of tensor: {tensor.shape}")
print(f"Datatype of tensor: {tensor.dtype}")
print(f"Device tensor is stored on: {tensor.device}")
```

    Shape of tensor: torch.Size([3, 4])
    Datatype of tensor: torch.float32
    Device tensor is stored on: cpu


### 1.1.3 Tensorçš„æ“ä½œ

ğŸ”—: https://pytorch.org/docs/stable/torch.html

å°†æœ¬åœ°CPUçš„tensorç§»åˆ°GPUï¼š


```python
if torch.cuda.is_available():
    tensor = tensor.to('cuda')
```

#### indexing and slicing


```python
tensor = torch.ones(4,4)
print('First row: ',tensor[0])
print('First column: ',tensor[:, 0])
print('Last cokumn:',tensor[...,-1])
tensor[:,1]=0
print(tensor)
```

    First row:  tensor([1., 1., 1., 1.])
    First column:  tensor([1., 1., 1., 1.])
    Last cokumn: tensor([1., 1., 1., 1.])
    tensor([[1., 0., 1., 1.],
            [1., 0., 1., 1.],
            [1., 0., 1., 1.],
            [1., 0., 1., 1.]])


#### Joining tensors


```python
# torch.cat
t1 = torch.cat([tensor, tensor, tensor], dim = 1) #dim=1è¡¨ç¤ºï¼Ÿ
print(t1)
```

    tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
            [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
            [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
            [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])



```python
#torch.stack æŸ¥çœ‹https://pytorch.org/docs/stable/generated/torch.stack.html
```

#### Arithmetic operations


```python
# çŸ©é˜µä¹˜æ³•ï¼Œy1,y2,y3å¾—åˆ°çš„æ˜¯åŒä¸€ä¸ªå€¼
y1 = tensor @ tensor.T #tensor.Tè¡¨ç¤ºtensorçš„è½¬ç½®ï¼Ÿ
y2 = tensor.matmul(tensor.T)
y3 = torch.rand_like(tensor) #rand_like?
torch.matmul(tensor, tensor.T, out=y3)

#ç‚¹ä¹˜(element-wise product)
z1 = tensor * tensor
z2 = tensor.mul(tensor)
z3 = torch.rand_like(tensor)
torch.mul(tensor, tensor, out=z3)
```




    tensor([[1., 0., 1., 1.],
            [1., 0., 1., 1.],
            [1., 0., 1., 1.],
            [1., 0., 1., 1.]])



#### Single-element tensors

å¯ä»¥å°†åªæœ‰ä¸€ä¸ªå…ƒç´ çš„tensorè½¬æ¢ä¸ºPythonçš„æ•´æ•°ã€æµ®ç‚¹æ•°ç±»å‹


```python
agg = tensor.sum()
agg_item = agg.item() #item()å¯ä»¥è½¬æ¢ç±»å‹
print(agg_item, type(agg_item))
```

    12.0 <class 'float'>


#### In-place operations

å°†ç»“æœæŒ‰ç…§ä½ç½®æ“ä½œåèµ‹å€¼åˆ°æœ¬èº«çš„æ“ä½œå«in placeï¼Œå’Œä¸€èˆ¬æ“ä½œæ¯”èµ·æ¥åªéœ€è¦åŠ ä¸Šåç¼€_å°±å¯ä»¥


```python
print(tensor, "\n")
tensor.t_()
print(tensor)
```

    tensor([[6., 6., 6., 6.],
            [5., 5., 5., 5.],
            [6., 6., 6., 6.],
            [6., 6., 6., 6.]]) 
    
    tensor([[6., 5., 6., 6.],
            [6., 5., 6., 6.],
            [6., 5., 6., 6.],
            [6., 5., 6., 6.]])



```python
print(tensor, "\n")
tensor.add_(5)
print(tensor)
```

    tensor([[6., 5., 6., 6.],
            [6., 5., 6., 6.],
            [6., 5., 6., 6.],
            [6., 5., 6., 6.]]) 
    
    tensor([[11., 10., 11., 11.],
            [11., 10., 11., 11.],
            [11., 10., 11., 11.],
            [11., 10., 11., 11.]])



```python
print(tensor, "\n")
tensor.t() #ä¸åŠ åç¼€åˆ™tensoræœ¬èº«ä¸å˜
print(tensor)
```

    tensor([[11., 10., 11., 11.],
            [11., 10., 11., 11.],
            [11., 10., 11., 11.],
            [11., 10., 11., 11.]]) 
    
    tensor([[11., 10., 11., 11.],
            [11., 10., 11., 11.],
            [11., 10., 11., 11.],
            [11., 10., 11., 11.]])


å› ä¸ºin placeæ“ä½œä¼šæ”¹å˜å˜é‡æœ¬èº«çš„å€¼ï¼Œæ‰€ä»¥ä¸æå€¡

### 1.1.4 ä¸Numpyçš„è¡”æ¥

#### Tensoråˆ°Numpy array


```python
t = torch.ones(5)
print(f"t: {t}")
n = t.numpy()   #ç”¨numpy()å°±å¥½äº†
print(f"n: {n}")
```

    t: tensor([1., 1., 1., 1., 1.])
    n: [1. 1. 1. 1. 1.]



```python
#å¯¹tensorçš„æ“ä½œä¹Ÿä¼šå½±å“åˆ°numpy array
t.add_(1)
print(f"t: {t}")
print(f"n: {n}")
```

    t: tensor([2., 2., 2., 2., 2.])
    n: [2. 2. 2. 2. 2.]


#### Numpy arrayåˆ°Tensor


```python
n = np.ones(5)
t = torch.from_numpy(n) #ç”¨from_numpy()å°±è¡Œ
```


```python
#å¯¹numpy arrayçš„æ“ä½œåŒæ ·ä¹Ÿå½±å“åˆ°tensor
np.add(n, 1, out=n)
print(f"t: {t}")
print(f"n: {n}")
```

    t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)
    n: [2. 2. 2. 2. 2.]


## 1.2 å¯¼å…¥æ•°æ®é›†ï¼ˆDatasets & Dataloadersï¼‰

Further reading: [torch.utils.data API](https://pytorch.org/docs/stable/data.html)

Pytorchä¸­æœ‰ä¸¤ä¸ªå‡½æ•°ï¼š
- `torch.utils.data.DataLoader`
- `torch.utils.data.Dataset`

Pytorchçš„domain librariesä¸­æä¾›äº†å·²ç»åŠ è½½çš„æ•°æ®é›†ä»¥åŠå¯¹è¯¥æ•°æ®é›†å¤„ç†çš„å…·ä½“å‡½æ•°ï¼Œå¯ä»¥ç”¨äºæµ‹è¯•è‡ªå·±å†™çš„modelï¼Œå…·ä½“å¯ä»¥åœ¨è¿™äº›åœ°æ–¹æ‰¾åˆ°ï¼š
- [Image Datasets](https://pytorch.org/image/stable/datasets.html)
- [Text Datasets](https://pytorch.org/text/stable/datasets.html)
- [Audio Datasets](https://pytorch.org/audio/stable/datasets.html)

### 1.2.1 åŠ è½½æ•°æ®é›†

ä»¥[Fashion-MNIST](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/)ä¸ºä¾‹å¯¼å…¥æ•°æ®é›†


```python
import torch
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor, Lambda
import matplotlib.pyplot as plt      #ç”»å›¾

training_data = datasets.FashionMNIST(
    root="data",                      #rootæŒ‡å®šdataçš„ç›®å½•
    train=True,                       #æ˜¯å¦è®­ç»ƒï¼ŒåŒºåˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    download=True,                    #åœ¨rootä¸­æ²¡æœ‰dataå°±åœ¨äº’è”ç½‘ä¸Šä¸‹è½½
    transform=ToTensor()              #æ•°æ®æœ‰æ—¶ä¸é€‚åˆç›´æ¥è®­ç»ƒï¼Œéœ€è¦æ”¹å˜æ ¼å¼å«åštransform
)

test_data = datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=ToTensor()
)
```

### 1.2.2 è®¿é—®å’Œå¯è§†åŒ–æ•°æ®é›†ï¼ˆIterating and Visualizing the Datasetï¼‰


```python
labels_map = {
    0: "T-Shirt",
    1: "Trouser",
    2: "Pullover",
    3: "Dress",
    4: "Coat",
    5: "Sandal",
    6: "Shirt",
    7: "Sneaker",
    8: "Bag",
    9: "Ankle Boot",
}
figure = plt.figure(figsize=(8,8))   #figsize?
cols, rows = 3, 3
for i in range(1, cols*rows + 1):
    sample_idx = torch.randint(len(training_data), size=(1,)).item()   #randintè¡¨ç¤º[a,b]ä¸­çš„éšæœºæ•°
    img, label = training_data[sample_idx]
    figure.add_subplot(rows, cols, i)
    plt.title(labels_map[label])
    plt.axis("off")
    plt.imshow(img.squeeze(), cmap="gray")
plt.show()
```


    
![png](output_60_0.png)
    


### 1.2.3 Creating a Custom Dataset for your files

ä»¥ FashionMNIST ä¸ºä¾‹ï¼Œiamgeså­˜åœ¨äº†`img_dir`,labelså­˜åœ¨äº†CSVï¼š`annotations_file`


```python
import os
import pandas as pd 
from torchvision.io import read_image

class CustomImageDataset(Dataset):   #transformè¡¨ç¤ºè½¬æ¢ç‰¹å¾æ ¼å¼ï¼Œtarget_transformæ”¹å˜æ ‡ç­¾æ ¼å¼
    def __init__(self, annotation_file, img_dir, transform=None, target_transform=None):
        self.img_labels = pd.read_csv(annotation_file)
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform
    
    def __len__(self):
        return len(self.img_labels)
    
    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])
        image = read_image(img_path)
        label = self.img_labels.iloc[idx,1]
        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
        sample = {"image": image, "label":label}
        return sample
```

A custom Dataset class must implement three functions:

- `__init__`

- `__len__`ï¼šè¿”å›æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°

- `__getitem__`

The `__getitem__` function loads and returns a sample from the dataset at the given index `idx`. Based on the index, it identifies the image's location on disk, converts that to a tensor using `read_image`, retrieves the corresponding label from the csv data `self.img_labels`, calls the transform functions on them(if applicable), and returns the tensor image and corresponding label in a Python dict.

### 1.2.4 DataLoaders

åœ¨å®é™…è®­ç»ƒæ¨¡å‹æ—¶ï¼Œéœ€è¦èƒ½å¤Ÿreshuffle the dataï¼ŒåŠ é€Ÿdata retrievalã€‚


```python
from torch.utils.data import DataLoader

train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)  #batch_size?
test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)
```

For finer-grained control over the data loading order, take a look at [Samplers](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)


```python
# Display image and label.
train_features, train_labels = next(iter(train_dataloader))
print(f"Feature batch shape: {train_features.size()}")
print(f"Labels batch shape: {train_labels.size()}")
img = train_features[0].squeeze()
label = train_labels[0]
plt.imshow(img, cmap="gray")
plt.show()
print(f"Label: {label}")
```

    Feature batch shape: torch.Size([64, 1, 28, 28])
    Labels batch shape: torch.Size([64])



    
![png](output_73_1.png)
    


    Label: 2


## 1.3 Transforms

The [torchvision.transforms]() module offers several commonly-used transforms out of the box.

éœ€è¦å°†æ•°æ®å’Œæ ‡ç­¾è½¬æ¢ä¸ºé€‚åˆè®­ç»ƒçš„æ ¼å¼ï¼Œå°±æ˜¯transformã€‚åˆ†åˆ«å¯¹åº”transformå’Œtarget_transformã€‚

The FashionMNIST features are in PIL Image format, and the labels are integers.For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors. To make these transformations, we use `ToTensor` and `Lambda`

scatterç”¨æ³•å¯çœ‹ï¼š[scatter_](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.scatter_)


```python
from torchvision import datasets
from torchvision.transforms import ToTensor, Lambda

ds = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=ToTensor(),
    '''
    torch.zeros create a zero tensor of size 10(æ•°æ®é›†ä¸­å…±æœ‰10ç§æ ‡ç­¾) and calls scatter_ which assigns 
    a value=1 on the index as given the lable y.
    '''
    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=10))
)
```

### ToTensor

[ToTensor]() converts a PIL image or NumPy `ndarray` into a `FloatTensor`, and scales the image's pixel intensity values in the range[0.,1.]

### Lambda Transforms

Lambda transforms apply any user-defined lambda function.


```python

```
